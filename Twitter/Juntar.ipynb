{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntemos los datos que juntamos los distintos días."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "david_21 = pd.read_csv('Datos/David/tweets_mayo_21_David.csv')\n",
    "david_22 = pd.read_csv('Datos/David/tweets_mayo_22_David.csv')\n",
    "david_23 = pd.read_csv('Datos/David/tweets_mayo_23_David.csv')\n",
    "david_24 = pd.read_csv('Datos/David/tweets_mayo_24_David.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "david = pd.concat([david_21, david_22, david_23, david_24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mario_21 = pd.read_csv('Datos/Mario/tweets_mayo_21_mario.csv')\n",
    "mario_22 = pd.read_csv('Datos/Mario/tweets_mayo_22_mario.csv')\n",
    "mario_23 = pd.read_csv('Datos/Mario/tweets_mayo_23_mario.csv')\n",
    "mario_24 = pd.read_csv('Datos/Mario/tweets_mayo_24_mario.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mario = pd.concat([mario_21, mario_22, mario_23, mario_24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_20 = pd.read_csv('Datos/Mario/tweets_mayo_20.csv')\n",
    "datos_21 = pd.concat([david_21, mario_21])\n",
    "datos_22 = pd.concat([david_22, mario_22])\n",
    "datos_23 = pd.concat([david_23, mario_23])\n",
    "datos_24 = pd.concat([david_24, mario_24])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Históricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "historicos_20 = pd.read_csv('Datos/Historicos/mayo_20.csv')\n",
    "historicos_20['created_at'] = historicos_20['created_at'].apply(lambda x:'2020-05-20 '+x[11:19])\n",
    "\n",
    "historicos_21 = pd.read_csv('Datos/Historicos/mayo_21.csv')\n",
    "historicos_21['created_at'] = historicos_21['created_at'].apply(lambda x:'2020-05-21 '+x[11:19])\n",
    "\n",
    "historicos_23 = pd.read_csv('Datos/Historicos/mayo_23.csv')\n",
    "historicos_23['created_at'] = historicos_23['created_at'].apply(lambda x:'2020-05-23 '+x[11:19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_20 = pd.concat([datos_20, historicos_20]).reset_index(drop=True)\n",
    "total_21 = pd.concat([datos_21, historicos_21]).reset_index(drop=True)\n",
    "total_22 = datos_22.copy()\n",
    "total_23 = pd.concat([datos_23, historicos_23]).reset_index(drop=True)\n",
    "total_24 = datos_24.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Únicamente los del stream\n",
    "totales = pd.concat([datos_20, datos_21, datos_22, datos_23, datos_24]).reset_index(drop = True)\n",
    "\n",
    "# Los del stream + históricos\n",
    "totales_historicos = pd.concat([total_20, total_21, total_22, total_23, total_24]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Únicamente los del stream\n",
    "totales['created_at'] = pd.to_datetime(totales['created_at'], format = '%Y-%m-%d %H:%M:%S')\n",
    "totales['day'] = totales['created_at'].apply(lambda x:x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los del stream + históricos\n",
    "totales_historicos['created_at'] = pd.to_datetime(totales_historicos['created_at'], format = '%Y-%m-%d %H:%M:%S')\n",
    "totales_historicos['day'] = totales_historicos['created_at'].apply(lambda x:x.day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora veámos cuántos tweets no repetidos tenemos por día con lo descargados desde el stream y juntando con los históricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tweets el 20 de mayo: 21086\n",
      "# tweets el 21 de mayo: 40840\n",
      "# tweets el 22 de mayo: 67996\n",
      "# tweets el 23 de mayo: 25494\n",
      "# tweets el 24 de mayo: 57981\n"
     ]
    }
   ],
   "source": [
    "# Únicamente los del stream\n",
    "for day in [20,21,22,23,24]:\n",
    "    count = totales[totales['day'] == day].drop_duplicates().shape[0]\n",
    "    print('# tweets el {0} de mayo: {1}'.format(day,count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# tweets el 20 de mayo: 51335\n",
      "# tweets el 21 de mayo: 50532\n",
      "# tweets el 22 de mayo: 67996\n",
      "# tweets el 23 de mayo: 51583\n",
      "# tweets el 24 de mayo: 57981\n"
     ]
    }
   ],
   "source": [
    "# Los del stream + históricos\n",
    "for day in [20,21,22,23,24]:\n",
    "    count = totales_historicos[totales_historicos['day'] == day].drop_duplicates().shape[0]\n",
    "    print('# tweets el {0} de mayo: {1}'.format(day,count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora escribamos los tweets no duplicados en un csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Únicamente los del stream\n",
    "totales = totales.sort_values(by = 'created_at')\n",
    "\n",
    "df_totales = []\n",
    "\n",
    "for day in [20,21,22,23,24]:\n",
    "    df = totales[totales['day'] == day].drop_duplicates().reset_index(drop = True)\n",
    "    df = df[['created_at','text','coordinates','hashtags']].loc[0:min(50000-1,df.shape[0])]   \n",
    "    \n",
    "    df_totales.append(df)\n",
    "    \n",
    "totales_sin_duplicados = pd.concat(df_totales).reset_index(drop=True)\n",
    "\n",
    "totales_sin_duplicados.to_csv('Datos/totales.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los del stream + históricos\n",
    "totales_historicos = totales_historicos.sort_values(by = 'created_at')\n",
    "\n",
    "df_totales = []\n",
    "\n",
    "for day in [20,21,22,23,24]:\n",
    "    df = totales_historicos[totales_historicos['day'] == day].drop_duplicates().reset_index(drop = True)\n",
    "    df = df[['created_at','text','coordinates','hashtags']].loc[0:min(50000-1,df.shape[0])]   \n",
    "    \n",
    "    df_totales.append(df)\n",
    "    \n",
    "totales_historicos_sin_duplicados = pd.concat(df_totales).reset_index(drop=True)\n",
    "\n",
    "totales_historicos_sin_duplicados.to_csv('Datos/totales_historicos.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
